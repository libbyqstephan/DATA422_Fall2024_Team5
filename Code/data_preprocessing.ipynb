{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seattle Building Data Pre-processing\n",
    "## Team 5 - Connor, John, Libby, & Natalie\n",
    "\n",
    "This file contains the code used to preprocess and clean our selected dataset. The final step will be outputting a cleaned and processed dataset as a new .csv file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Volumes/T7/DATA422_Fall2024_Team5'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Makes paths work if you just clone or pull the repo\n",
    "import os\n",
    "os.chdir('../')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#Install Required Libraries (Only needs to run once)\n",
    "%pip install -q pandas numpy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Paths\n",
    "PATH_TO_DATASET = \"Data/Seattle Building Energy Benchmarking/2022_Building_Energy_Benchmarking_20240906.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['OSEBuildingID', 'DataYear', 'BuildingName', 'BuildingType',\n",
      "       'TaxParcelIdentificationNumber', 'Address', 'City', 'State', 'ZipCode',\n",
      "       'Latitude', 'Longitude', 'Neighborhood', 'CouncilDistrictCode',\n",
      "       'YearBuilt', 'NumberofFloors', 'NumberofBuildings', 'PropertyGFATotal',\n",
      "       'PropertyGFABuilding(s)', 'PropertyGFAParking', 'ENERGYSTARScore',\n",
      "       'SiteEUIWN(kBtu/sf)', 'SiteEUI(kBtu/sf)', 'SiteEnergyUse(kBtu)',\n",
      "       'SiteEnergyUseWN(kBtu)', 'SourceEUIWN(kBtu/sf)', 'SourceEUI(kBtu/sf)',\n",
      "       'EPAPropertyType', 'LargestPropertyUseType',\n",
      "       'LargestPropertyUseTypeGFA', 'SecondLargestPropertyUseType',\n",
      "       'SecondLargestPropertyUseTypeGFA', 'ThirdLargestPropertyUseType',\n",
      "       'ThirdLargestPropertyUseTypeGFA', 'Electricity(kWh)', 'SteamUse(kBtu)',\n",
      "       'NaturalGas(therms)', 'ComplianceStatus', 'ComplianceIssue',\n",
      "       'Electricity(kBtu)', 'NaturalGas(kBtu)', 'TotalGHGEmissions',\n",
      "       'GHGEmissionsIntensity'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#Import Dataset\n",
    "building_DF = pd.read_csv(PATH_TO_DATASET)\n",
    "\n",
    "building_DF.head()\n",
    "print(building_DF.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop Columns That We Decided Not To Use\n",
    "Dropped_Columns = ['TaxParcelIdentificationNumber', 'City', 'State', 'CouncilDistrictCode', 'PropertyGFABuilding(s)', \n",
    "                   'PropertyGFAParking', 'SiteEUIWN(kBtu/sf)', 'SiteEnergyUse(kBtu)', 'SiteEnergyUseWN(kBtu)', \n",
    "                   'SourceEUIWN(kBtu/sf)', 'LargestPropertyUseType', 'LargestPropertyUseTypeGFA', \n",
    "                   'SecondLargestPropertyUseType', 'SecondLargestPropertyUseTypeGFA', 'ThirdLargestPropertyUseType',\n",
    "                   'ThirdLargestPropertyUseTypeGFA', 'Electricity(kWh)', 'NaturalGas(therms)', 'TotalGHGEmissions']\n",
    "#Drop Listed Columns\n",
    "df_after_drop = building_DF.drop(columns=Dropped_Columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       Null Count Data Type\n",
      "SteamUse(kBtu)               3517   float64\n",
      "NaturalGas(kBtu)             1669   float64\n",
      "ENERGYSTARScore              1174   float64\n",
      "SourceEUI(kBtu/sf)            458   float64\n",
      "SiteEUI(kBtu/sf)              458   float64\n",
      "EPAPropertyType               234    object\n",
      "GHGEmissionsIntensity         209   float64\n",
      "Electricity(kBtu)             208   float64\n",
      "Neighborhood                    1    object\n"
     ]
    }
   ],
   "source": [
    "# Column wise Null counts\n",
    "column_nulls = df_after_drop.isnull().sum()\n",
    "sorted_column_nulls = column_nulls[column_nulls > 0].sort_values(ascending=False)\n",
    "column_dtypes = df_after_drop.dtypes\n",
    "nulls_and_dtypes = pd.DataFrame({\n",
    "    'Null Count': sorted_column_nulls,\n",
    "    'Data Type': column_dtypes[sorted_column_nulls.index]\n",
    "})\n",
    "\n",
    "print(nulls_and_dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Column  by Column examination of values based on Data Wrangler view.\n",
    "\n",
    "SteamUse - 96% missing - There are 19 '0.0' entries so its possible that Null values are improperly entered zeros. Another possibility is that these buildings don't have steam which is why they are null and the 0.0 entries are buildings with steam that didn't use any.\n",
    "Options: Drop column, or fill Nulls with 0.\n",
    "\n",
    "NaturalGas(kBtu) - 46% - Has zero values, nulls are likely from buildings that don't use natural gas.\n",
    "Options: Replace Nulls with 0.0, Replace Nulls with -1.0, replace with mean/median\n",
    "\n",
    "ENERGYSTARScore - 32% - Nulls could be buildings that don't have Energy Star Scores calculated yet\n",
    "Options: Replace with 0.0, replace with -1, replace with mean/median\n",
    "\n",
    "SourceEUI(kBtu/sf)\n",
    "\n",
    "SiteEUI(kBtu/sf)\n",
    "\n",
    "EPAPropertyType - Replace Nulls with Other or Mode Category\n",
    "\n",
    "GHGEmissionsIntensity - Drop Rows with Missing values?\n",
    "\n",
    "Electricity(kBtu) - Fill with median/mode or drop rows with missing values?\n",
    "\n",
    "Neighborhood - drop the single missing value row\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_null_values(b_df):\n",
    "    '''This function takes the building dataframe and returns a new dataframe with the null values handled'''\n",
    "    b_df = b_df['SteamUse(kBtu)'].fillna(0.0) #Buildings that dont have steam have zero steam use\n",
    "    b_df = b_df['ThirdLargestPropertyUseType'].fillna('None') #Buildings that dont have a third largest property use type have none\n",
    "    b_df = b_df['ThiirdLargestPropertyUseTypeGFA'].fillna(-1) #marks that a building has no 3rd largest property\n",
    "    b_df = b_df['SecondLargestPropertyUseType'].fillna('None') #Buildings that dont have a second largest property use type have none\n",
    "    b_df = b_df['SecondLargestPropertyUseTypeGFA'].fillna(-1) #marks that a building has no 2nd largest property\n",
    "    b_df = b_df['NaturalGas(therms)'].fillna(0.0) #Buildings that don't have natural gas use zero natural gas\n",
    "    b_df = b_df['NaturalGas(kBtu)'].fillna(0.0) #Buildings that don't have natural gas use zero natural gas\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Processing Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoding\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "cat_cols = []\n",
    "num_cols = []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Export Processed Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(building_DF)\n",
    "building_DF.to_csv('Data/PP_Building_Energy_Benchmarking.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
